training_args:

  ### Discriminator Config ###
  use_patchgan: True                            # Do you want to use PatchGAN?
  disc_start_dim: 64                            # PatchGAN starting channel dim
  disc_depth: 3                                 # PatchGAN Depth
  disc_kernel_size: 4                           # PatchGAN Conv Kernel Size
  disc_leaky_relu: 0.2                          # PatchGAN LeakyReLU Slop
  disc_learning_rate: 0.00005                   # Discriminator Learning Rate
  disc_lr_scheduler: constant_with_warmup       # Discriminator LR Scheduler "constant", "constant_with_warmup", "linear", "cosine"
  disc_lr_warmup_steps: 500                     # Discriminator LR Warmup Steps
  disc_start: 50000                             # Discriminator Delayed Starting Iteration
  disc_weight: 0.5                              # Discriminator Loss Weight

  ### LPIPS Config ###
  use_lpips: True                               # Do you want to use LPIPS Perceptual Loss?
  use_lpips_package: True                       # Do you want to use the LPIPS package or our own implementation?
  lpips_checkpoint: lpips_vgg.pt                # If using our own lpips, give the path to the pretrained checkpoint
  lpips_weight: 0.5                             # LPIPS loss weight

  ### Training Config ###
  learning_rate: 0.00005                        # VAE Training Learning Rate
  lr_scheduler: constant_with_warmup            # LR Scheduler
  lr_warmup_steps: 1500                         # LR Warmup Steps
  total_training_iterations: 400000             # Total Training Iterations
  checkpoint_iterations: 5000                   # Checkpoint Iteration Frequency
  per_gpu_batch_size: 12                        # Batch per GPU (multipled by n_gpus in accelerate)
  gradient_accumulations_steps: 1               # Split per GPU batch into accumulation steps
  max_grad_norm: 1.0                            # Max Grad Norm for Clipping
  reconstruction_loss_fn: l1                    # What Reconstruction Loss do you want? ("l1", "l2")
  num_val_random_samples: 8                     # How many random samples do you want to plot reconstructions for? (max of the set batch per gpu)
  val_img_folder_path: null                     # Folder of images you want to plot during training, if you dont want to random sample
  val_generation_freq: 250                      # How often do you want to test generations?
  pixelwise_average: True                       # Do you want to average all the pixels (True) or sum pixels and average the batch (False)
  optimizer_beta1: 0.9                          # VAdamW Optimizer Beta1
  optimizer_beta2: 0.999                        # AdamW Optimizer Beta2
  optimizer_weight_decay: 0.005                 # AdamW Optimizer Weight Decay

  ### Dataset Config ###
  pin_memory: True                              # Do you want to pin_memory on Dataloader?
  num_workers: 32                               # Number of CPU workers for DataLoading
  random_resize: False                          # Do you want to random resize in image transforms. If false, defauls to resize
  interpolation: bilinear                       # What interpolation mode do you want to use? ("nearest", "bilinear", "bicubic")
  random_flip_p: 0.0                            # Random Horizontal Flip Probability
